/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

// AI Core GLM Chat Service
// è´Ÿè´£å¤„ç† GLM æ¨¡å‹çš„å¯¹è¯è¯·æ±‚ï¼ŒåŒ…æ‹¬æµå¼è¾“å‡ºã€å·¥å…·è°ƒç”¨ã€æ·±åº¦æ€è€ƒã€è”ç½‘æœç´¢
// å‚è€ƒæ–‡æ¡£:
// - æ·±åº¦æ€è€ƒ: https://docs.bigmodel.cn/cn/guide/capabilities/thinking
// - è”ç½‘æœç´¢: https://docs.bigmodel.cn/cn/guide/tools/web-search

import { createDecorator } from '../../../../platform/instantiation/common/instantiation.js';
import { InstantiationType, registerSingleton } from '../../../../platform/instantiation/common/extensions.js';
import { ILogService } from '../../../../platform/log/common/log.js';
import { IConfigurationService } from '../../../../platform/configuration/common/configuration.js';
import { Disposable } from '../../../../base/common/lifecycle.js';
import { URI } from '../../../../base/common/uri.js';
import { CancellationToken } from '../../../../base/common/cancellation.js';

// ============================================================================
// ç±»å‹å®šä¹‰
// ============================================================================

export interface GLMMessage {
	role: 'system' | 'user' | 'assistant' | 'tool';
	content?: string;
	tool_calls?: GLMToolCall[];
	tool_call_id?: string;
}

export interface GLMToolCall {
	id: string;
	type: 'function';
	function: {
		name: string;
		arguments: string;
	};
}

export interface GLMToolDefinition {
	type: 'function' | 'web_search';
	function?: {
		name: string;
		description: string;
		parameters: {
			type: 'object';
			properties: Record<string, { type: string; description: string }>;
			required?: string[];
		};
	};
	web_search?: {
		enable: boolean;
		search_engine?: 'search_std' | 'search_pro' | 'search_pro_sogou' | 'search_pro_quark';
		search_result?: boolean;
	};
}

export interface GLMStreamEvent {
	type: 'thinking' | 'content' | 'tool_call' | 'tool_result' | 'web_search' | 'done' | 'error' | 'truncated';
	content?: string;
	toolCall?: GLMToolCall;
	toolResult?: { id: string; output: string; success: boolean };
	webSearchResults?: WebSearchResult[];
	error?: string;
	reason?: string; // ç”¨äº truncated äº‹ä»¶
}

export interface WebSearchResult {
	title: string;
	link: string;
	content: string;
	media?: string;
	icon?: string;
}

export interface GLMChatContext {
	files: Array<{
		uri: URI;
		path: string;
		content: string;
		language?: string;
		lineRange?: string;
	}>;
	webSearchResults?: WebSearchResult[];
}

export interface GLMChatOptions {
	model?: string;
	temperature?: number;
	maxTokens?: number;
	tools?: GLMToolDefinition[];
	/** å¯ç”¨æ·±åº¦æ€è€ƒæ¨¡å¼ */
	enableThinking?: boolean;
	/** å¯ç”¨è”ç½‘æœç´¢ */
	enableWebSearch?: boolean;
	/** æœç´¢å¼•æ“ç±»å‹ */
	searchEngine?: 'search_std' | 'search_pro' | 'search_pro_sogou' | 'search_pro_quark';
	/** ä¼šè¯ IDï¼Œç”¨äºå…³è”ä¸Šä¸‹æ–‡ */
	sessionId?: string;
}

export interface GLMTaskRoutingPlan {
	complexity: 'simple' | 'medium' | 'hard';
	subAgent: 'quick_responder' | 'implementation_agent' | 'planning_agent';
	model: string;
	requiresVision: boolean;
	enableThinking: boolean;
	enableWebSearch: boolean;
	maxTokens: number;
	reason: string;
	confidence: number;
}

// ============================================================================
// ä¼šè¯ç®¡ç† - æ”¯æŒä¸Šä¸‹æ–‡ç¼“å­˜
// å‚è€ƒ: https://docs.bigmodel.cn/cn/guide/capabilities/cache
// ============================================================================

export interface ChatSession {
	id: string;
	messages: GLMMessage[];
	createdAt: Date;
	updatedAt: Date;
	/** ç¼“å­˜ç»Ÿè®¡ */
	cacheStats: {
		totalTokens: number;
		cachedTokens: number;
	};
}

// ============================================================================
// æœåŠ¡æ¥å£
// ============================================================================

export const IGLMChatService = createDecorator<IGLMChatService>('glmChatService');

export interface IGLMChatService {
	readonly _serviceBrand: undefined;

	/**
	 * æµå¼å‘é€æ¶ˆæ¯ï¼Œè¿”å›äº‹ä»¶æµ
	 */
	streamChat(
		messages: GLMMessage[],
		context: GLMChatContext,
		options?: GLMChatOptions,
		token?: CancellationToken
	): AsyncIterable<GLMStreamEvent>;

	/**
	 * æ”¯æŒè‡ªåŠ¨ç»­æ¥çš„æµå¼èŠå¤©
	 * å½“å“åº”å›  token é™åˆ¶æˆªæ–­æ—¶ï¼Œè‡ªåŠ¨å‘èµ·ç»­æ¥è¯·æ±‚
	 */
	streamChatWithContinuation(
		messages: GLMMessage[],
		context: GLMChatContext,
		options?: GLMChatOptions,
		token?: CancellationToken,
		maxContinuations?: number
	): AsyncGenerator<GLMStreamEvent>;

	/**
	 * æ„å»ºç³»ç»Ÿæç¤ºè¯
	 */
	buildSystemPrompt(context: GLMChatContext, mode: 'chat' | 'agent', chatMode?: 'vibe' | 'spec'): string;

	/**
	 * æ‰§è¡Œè”ç½‘æœç´¢
	 */
	webSearch(query: string): Promise<WebSearchResult[]>;

	/**
	 * æµ‹è¯•è¿æ¥
	 */
	testConnection(): Promise<boolean>;

	/**
	 * æ£€æŸ¥æ·±åº¦æ€è€ƒæ¨¡å¼æ˜¯å¦å¼€å¯
	 */
	isThinkingEnabled(): boolean;

	/**
	 * æ£€æŸ¥è”ç½‘æœç´¢æ˜¯å¦å¼€å¯
	 */
	isWebSearchEnabled(): boolean;

	// ========================================================================
	// ä¼šè¯ç®¡ç† - æ”¯æŒä¸Šä¸‹æ–‡ç¼“å­˜
	// å‚è€ƒ: https://docs.bigmodel.cn/cn/guide/capabilities/cache
	// ========================================================================

	/**
	 * åˆ›å»ºæ–°ä¼šè¯
	 * @param systemPrompt å¯é€‰çš„ç³»ç»Ÿæç¤ºè¯
	 */
	createSession(systemPrompt?: string): ChatSession;

	/**
	 * è·å–å½“å‰ä¼šè¯
	 */
	getCurrentSession(): ChatSession | undefined;

	/**
	 * è·å–æŒ‡å®šä¼šè¯
	 */
	getSession(sessionId: string): ChatSession | undefined;

	/**
	 * æ¸…é™¤ä¼šè¯å†å²
	 */
	clearSession(sessionId?: string): void;

	/**
	 * æ·»åŠ æ¶ˆæ¯åˆ°ä¼šè¯ï¼ˆæ‰‹åŠ¨ç®¡ç†ï¼‰
	 */
	addMessage(sessionId: string, message: GLMMessage): void;

	/**
	 * è·å–ä¼šè¯çš„å®Œæ•´æ¶ˆæ¯åˆ—è¡¨ï¼ˆç”¨äºä¸Šä¸‹æ–‡ç¼“å­˜ï¼‰
	 */
	getSessionMessages(sessionId: string): GLMMessage[];

	/**
	 * æµå¼èŠå¤©ï¼ˆå¸¦ä¼šè¯ä¸Šä¸‹æ–‡ï¼‰
	 * è‡ªåŠ¨ç»´æŠ¤å¯¹è¯å†å²ï¼Œåˆ©ç”¨æ™ºè°± AI çš„ä¸Šä¸‹æ–‡ç¼“å­˜åŠŸèƒ½
	 */
	streamChatWithSession(
		userMessage: string,
		context: GLMChatContext,
		options?: GLMChatOptions,
		token?: CancellationToken
	): AsyncIterable<GLMStreamEvent>;

	/**
	 * è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
	 */
	getCacheStats(sessionId?: string): { totalTokens: number; cachedTokens: number; savings: string };

	/**
	 * ä½¿ç”¨ GLM-5 åšå‰ç½®ä»»åŠ¡åˆ†æï¼Œè¿”å›è‡ªåŠ¨è·¯ç”±è®¡åˆ’
	 */
	analyzeTaskAndRoute(userMessage: string, context: GLMChatContext, chatMode: 'vibe' | 'spec', isAgentMode: boolean, forceRouter?: boolean): Promise<GLMTaskRoutingPlan>;
}

// ============================================================================
// æœåŠ¡å®ç°
// ============================================================================

export class GLMChatService extends Disposable implements IGLMChatService {
	readonly _serviceBrand: undefined;

	private readonly API_ENDPOINT = 'https://open.bigmodel.cn/api/paas/v4/chat/completions';
	private readonly DEFAULT_API_KEY = '20cca2b90c8c4348aaab3d4f6814c33b.Ow4WJfqfc06uB4KI';
	private readonly DEFAULT_MODEL = 'glm-4.7';
	private readonly ROUTER_MODEL = 'glm-5';

	// ========================================================================
	// ä¼šè¯ç®¡ç† - æ”¯æŒä¸Šä¸‹æ–‡ç¼“å­˜
	// ========================================================================
	private readonly _sessions: Map<string, ChatSession> = new Map();
	private _currentSessionId: string | undefined;

	/** æœ€å¤§å†å²æ¶ˆæ¯æ•°é‡ï¼ˆé¿å…è¶…å‡º token é™åˆ¶ï¼‰ */
	private readonly MAX_HISTORY_MESSAGES = 50;

	/** æœ€å¤§å†å² token ä¼°ç®—ï¼ˆçº¦ 100Kï¼Œç•™ 28K ç»™æ–°æ¶ˆæ¯å’Œè¾“å‡ºï¼‰ */
	private readonly MAX_HISTORY_TOKENS = 100000;

	constructor(
		@ILogService private readonly logService: ILogService,
		@IConfigurationService private readonly configurationService: IConfigurationService,
	) {
		super();
	}

	// ========================================================================
	// ä¼šè¯ç®¡ç†æ–¹æ³•å®ç°
	// ========================================================================

	createSession(systemPrompt?: string): ChatSession {
		const sessionId = `session-${Date.now()}-${Math.random().toString(36).slice(2, 8)}`;

		const session: ChatSession = {
			id: sessionId,
			messages: [],
			createdAt: new Date(),
			updatedAt: new Date(),
			cacheStats: {
				totalTokens: 0,
				cachedTokens: 0
			}
		};

		// å¦‚æœæœ‰ç³»ç»Ÿæç¤ºè¯ï¼Œæ·»åŠ ä¸ºç¬¬ä¸€æ¡æ¶ˆæ¯
		if (systemPrompt) {
			session.messages.push({
				role: 'system',
				content: systemPrompt
			});
		}

		this._sessions.set(sessionId, session);
		this._currentSessionId = sessionId;

		this.logService.info(`[GLMChatService] Created session: ${sessionId}`);
		return session;
	}

	getCurrentSession(): ChatSession | undefined {
		if (!this._currentSessionId) {
			return undefined;
		}
		return this._sessions.get(this._currentSessionId);
	}

	getSession(sessionId: string): ChatSession | undefined {
		return this._sessions.get(sessionId);
	}

	clearSession(sessionId?: string): void {
		if (sessionId) {
			this._sessions.delete(sessionId);
			if (this._currentSessionId === sessionId) {
				this._currentSessionId = undefined;
			}
			this.logService.info(`[GLMChatService] Cleared session: ${sessionId}`);
		} else {
			// æ¸…é™¤å½“å‰ä¼šè¯
			if (this._currentSessionId) {
				this._sessions.delete(this._currentSessionId);
				this._currentSessionId = undefined;
			}
			this.logService.info(`[GLMChatService] Cleared current session`);
		}
	}

	addMessage(sessionId: string, message: GLMMessage): void {
		const session = this._sessions.get(sessionId);
		if (!session) {
			this.logService.warn(`[GLMChatService] Session not found: ${sessionId}`);
			return;
		}

		session.messages.push(message);
		session.updatedAt = new Date();

		// ç®¡ç†å†å²é•¿åº¦ï¼Œé¿å…è¶…å‡ºé™åˆ¶
		this.trimSessionHistory(session);
	}

	getSessionMessages(sessionId: string): GLMMessage[] {
		const session = this._sessions.get(sessionId);
		// è¿”å›æ·±æ‹·è´ï¼Œé¿å…å¤–éƒ¨ä¿®æ”¹å½±å“åŸå§‹ä¼šè¯å†å²
		return session?.messages.map(m => ({ ...m })) || [];
	}

	/**
	 * ä¿®å‰ªä¼šè¯å†å²ï¼Œé¿å…è¶…å‡º token é™åˆ¶
	 * ä¿ç•™ç³»ç»Ÿæç¤ºè¯å’Œæœ€è¿‘çš„æ¶ˆæ¯
	 */
	private trimSessionHistory(session: ChatSession): void {
		const messages = session.messages;

		// å¦‚æœæ¶ˆæ¯æ•°é‡è¶…è¿‡é™åˆ¶
		if (messages.length > this.MAX_HISTORY_MESSAGES) {
			// ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯
			const systemMessages = messages.filter(m => m.role === 'system');
			const nonSystemMessages = messages.filter(m => m.role !== 'system');

			// ä¿ç•™æœ€è¿‘çš„æ¶ˆæ¯
			const recentMessages = nonSystemMessages.slice(-this.MAX_HISTORY_MESSAGES + systemMessages.length);

			session.messages = [...systemMessages, ...recentMessages];
			this.logService.info(`[GLMChatService] Trimmed session history from ${messages.length} to ${session.messages.length} messages`);
		}

		// ä¼°ç®— token æ•°é‡å¹¶è¿›ä¸€æ­¥ä¿®å‰ª
		const estimatedTokens = this.estimateTokens(session.messages);
		if (estimatedTokens > this.MAX_HISTORY_TOKENS) {
			const systemMessages = session.messages.filter(m => m.role === 'system');
			const nonSystemMessages = session.messages.filter(m => m.role !== 'system');

			// é€æ­¥ç§»é™¤æ—§æ¶ˆæ¯ç›´åˆ° token æ•°é‡åˆé€‚
			while (nonSystemMessages.length > 2 && this.estimateTokens([...systemMessages, ...nonSystemMessages]) > this.MAX_HISTORY_TOKENS) {
				nonSystemMessages.shift();
			}

			session.messages = [...systemMessages, ...nonSystemMessages];
			this.logService.info(`[GLMChatService] Trimmed session to fit token limit: ~${this.estimateTokens(session.messages)} tokens`);
		}
	}

	/**
	 * ä¼°ç®—æ¶ˆæ¯çš„ token æ•°é‡ï¼ˆç²—ç•¥ä¼°è®¡ï¼šä¸­æ–‡çº¦ 2 å­—ç¬¦/tokenï¼Œè‹±æ–‡çº¦ 4 å­—ç¬¦/tokenï¼‰
	 */
	private estimateTokens(messages: GLMMessage[]): number {
		let totalChars = 0;
		for (const msg of messages) {
			if (msg.content) {
				totalChars += msg.content.length;
			}
		}
		// ç²—ç•¥ä¼°è®¡ï¼šå¹³å‡ 3 å­—ç¬¦/token
		return Math.ceil(totalChars / 3);
	}

	/**
	 * æµå¼èŠå¤©ï¼ˆå¸¦ä¼šè¯ä¸Šä¸‹æ–‡ï¼‰
	 * è‡ªåŠ¨ç»´æŠ¤å¯¹è¯å†å²ï¼Œåˆ©ç”¨æ™ºè°± AI çš„ä¸Šä¸‹æ–‡ç¼“å­˜åŠŸèƒ½
	 */
	async *streamChatWithSession(
		userMessage: string,
		context: GLMChatContext,
		options?: GLMChatOptions,
		token?: CancellationToken
	): AsyncIterable<GLMStreamEvent> {
		// è·å–æˆ–åˆ›å»ºä¼šè¯
		let session = options?.sessionId
			? this.getSession(options.sessionId)
			: this.getCurrentSession();

		if (!session) {
			// åˆ›å»ºæ–°ä¼šè¯ï¼Œä½¿ç”¨å½“å‰æ¨¡å¼æ„å»ºç³»ç»Ÿæç¤ºè¯
			const isAgentMode = this.configurationService.getValue<boolean>('aiCore.agentMode') !== false;
			const chatMode = this.configurationService.getValue<'vibe' | 'spec'>('aiCore.defaultChatMode') || 'vibe';
			const systemPrompt = this.buildSystemPrompt(context, isAgentMode ? 'agent' : 'chat', chatMode);
			session = this.createSession(systemPrompt);
			this.logService.info(`[GLMChatService] Auto-created session for chat: ${session.id}`);
		}

		// æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°ä¼šè¯
		this.addMessage(session.id, {
			role: 'user',
			content: userMessage
		});

		// æ„å»ºå®Œæ•´çš„æ¶ˆæ¯åˆ—è¡¨ï¼ˆåˆ©ç”¨ä¸Šä¸‹æ–‡ç¼“å­˜ï¼‰
		const messages = this.getSessionMessages(session.id);

		this.logService.info(`[GLMChatService] Sending chat with ${messages.length} messages (session: ${session.id})`);

		// æ”¶é›†åŠ©æ‰‹å›å¤
		let assistantContent = '';

		// ä½¿ç”¨æµå¼èŠå¤©
		for await (const event of this.streamChatWithContinuation(messages, context, options, token)) {
			// æ”¶é›†å†…å®¹ç”¨äºæ·»åŠ åˆ°å†å²
			if (event.type === 'content' && event.content) {
				assistantContent += event.content;
			}

			yield event;
		}

		// æ·»åŠ åŠ©æ‰‹å›å¤åˆ°ä¼šè¯å†å²
		if (assistantContent) {
			this.addMessage(session.id, {
				role: 'assistant',
				content: assistantContent
			});
			this.logService.info(`[GLMChatService] Added assistant response to session (${assistantContent.length} chars)`);
		}
	}

	getCacheStats(sessionId?: string): { totalTokens: number; cachedTokens: number; savings: string } {
		const session = sessionId ? this.getSession(sessionId) : this.getCurrentSession();
		if (!session) {
			return { totalTokens: 0, cachedTokens: 0, savings: '0%' };
		}

		const { totalTokens, cachedTokens } = session.cacheStats;
		const savingsPercent = totalTokens > 0 ? ((cachedTokens / totalTokens) * 100).toFixed(1) : '0';

		return {
			totalTokens,
			cachedTokens,
			savings: `${savingsPercent}%`
		};
	}

	/**
	 * æ›´æ–°ç¼“å­˜ç»Ÿè®¡ï¼ˆä» API å“åº”ä¸­æå–ï¼‰
	 */
	private updateCacheStats(sessionId: string, usage: { prompt_tokens?: number; prompt_tokens_details?: { cached_tokens?: number } }): void {
		const session = this._sessions.get(sessionId);
		if (!session) {
			return;
		}

		if (usage.prompt_tokens) {
			session.cacheStats.totalTokens += usage.prompt_tokens;
		}
		if (usage.prompt_tokens_details?.cached_tokens) {
			session.cacheStats.cachedTokens += usage.prompt_tokens_details.cached_tokens;
			this.logService.info(`[GLMChatService] Cache hit: ${usage.prompt_tokens_details.cached_tokens} tokens cached`);
		}
	}

	private getApiKey(): string {
		return this.configurationService.getValue<string>('aiCore.glmApiKey') || this.DEFAULT_API_KEY;
	}

	private getModel(): string {
		return this.configurationService.getValue<string>('aiCore.glmModel') || this.DEFAULT_MODEL;
	}

	private isAutoRoutingEnabled(): boolean {
		return this.configurationService.getValue<boolean>('aiCore.enableAutoModelRouting') !== false;
	}

	private isVisionRoutingEnabled(): boolean {
		return this.configurationService.getValue<boolean>('aiCore.enableVisionRouting') !== false;
	}

	private getModelByComplexity(complexity: 'simple' | 'medium' | 'hard'): string {
		if (complexity === 'simple') {
			return this.configurationService.getValue<string>('aiCore.routingModelSimple') || 'glm-4.7-flash';
		}
		if (complexity === 'medium') {
			return this.configurationService.getValue<string>('aiCore.routingModelMedium') || 'glm-4.7';
		}
		return this.configurationService.getValue<string>('aiCore.routingModelHard') || 'glm-5';
	}

	private getVisionModelByComplexity(complexity: 'simple' | 'medium' | 'hard'): string {
		if (complexity === 'simple') {
			return this.configurationService.getValue<string>('aiCore.routingVisionModelSimple') || 'glm-4.6v-flash';
		}
		if (complexity === 'medium') {
			return this.configurationService.getValue<string>('aiCore.routingVisionModelMedium') || 'glm-4.6v-flashx';
		}
		return this.configurationService.getValue<string>('aiCore.routingVisionModelHard') || 'glm-4.6v';
	}

	private hasVisualInputs(userMessage: string, context: GLMChatContext): boolean {
		const visualExtRe = /\.(png|jpg|jpeg|webp|gif|bmp|svg|mp4|mov|avi|mkv|webm|pdf)$/i;
		const hasVisualFile = context.files.some(f => visualExtRe.test(f.path) || f.language === 'binary');
		const hasVisualIntent = /å›¾ç‰‡|å›¾åƒ|çœ‹å›¾|è¯†å›¾|æˆªå›¾|è§†é¢‘|å¤šæ¨¡æ€|è§†è§‰|ocr|pdf|æ–‡æ¡£è§£æ|image|video|vision/i.test(userMessage);
		return hasVisualFile || hasVisualIntent;
	}

	private getFallbackRoutingPlan(userMessage: string): GLMTaskRoutingPlan {
		const len = userMessage.length;
		const hasCodeIntent = /ä»£ç |ä¿®å¤|è°ƒè¯•|å®ç°|é‡æ„|æ¶æ„|è®¾è®¡|æ€§èƒ½|bug|error|refactor|implement|debug/i.test(userMessage);
		const hasPlanningIntent = /æ–¹æ¡ˆ|æ¶æ„|è®¾è®¡|è§„åˆ’|spec|éœ€æ±‚|ä»»åŠ¡åˆ†è§£|trade-?off/i.test(userMessage);

		if (hasPlanningIntent || len > 500) {
			return {
				complexity: 'hard',
				subAgent: 'planning_agent',
				model: this.getModelByComplexity('hard'),
				requiresVision: false,
				enableThinking: true,
				enableWebSearch: true,
				maxTokens: 32768,
				reason: 'æœ¬åœ°å¯å‘å¼åˆ¤å®šä¸ºå¤æ‚è§„åˆ’ç±»ä»»åŠ¡',
				confidence: 0.62
			};
		}

		if (hasCodeIntent || len > 120) {
			return {
				complexity: 'medium',
				subAgent: 'implementation_agent',
				model: this.getModelByComplexity('medium'),
				requiresVision: false,
				enableThinking: true,
				enableWebSearch: true,
				maxTokens: 16384,
				reason: 'æœ¬åœ°å¯å‘å¼åˆ¤å®šä¸ºä¸­ç­‰å®ç°ç±»ä»»åŠ¡',
				confidence: 0.58
			};
		}

		return {
			complexity: 'simple',
			subAgent: 'quick_responder',
			model: this.getModelByComplexity('simple'),
			requiresVision: false,
			enableThinking: false,
			enableWebSearch: false,
			maxTokens: 8192,
			reason: 'æœ¬åœ°å¯å‘å¼åˆ¤å®šä¸ºç®€å•é—®ç­”',
			confidence: 0.55
		};
	}

	async analyzeTaskAndRoute(userMessage: string, context: GLMChatContext, chatMode: 'vibe' | 'spec', isAgentMode: boolean, forceRouter: boolean = false): Promise<GLMTaskRoutingPlan> {
		if (!this.isAutoRoutingEnabled() && !forceRouter) {
			return {
				complexity: 'medium',
				subAgent: 'implementation_agent',
				model: this.getModel(),
				requiresVision: false,
				enableThinking: this.isThinkingEnabled(),
				enableWebSearch: this.isWebSearchEnabled(),
				maxTokens: 16384,
				reason: 'è‡ªåŠ¨è·¯ç”±å·²å…³é—­ï¼Œä½¿ç”¨é»˜è®¤é…ç½®',
				confidence: 1
			};
		}

		const hasVisionInputs = this.hasVisualInputs(userMessage, context) && this.isVisionRoutingEnabled();
		const prompt = [
			'ä½ æ˜¯ä¸€ä¸ªä»»åŠ¡è·¯ç”±å™¨ã€‚è¯·è¯„ä¼°ç”¨æˆ·è¯·æ±‚éš¾åº¦å¹¶è¿”å› JSONï¼Œä¸è¦è¾“å‡ºå…¶ä»–å†…å®¹ã€‚',
			'å¯é€‰å¤æ‚åº¦ï¼šsimple | medium | hard',
			'å¯é€‰å­ä»£ç†ï¼šquick_responder | implementation_agent | planning_agent',
			'æ˜¯å¦éœ€è¦è§†è§‰æ¨¡å‹ï¼šrequiresVision=true|false',
			'ä»…è¿”å›å¦‚ä¸‹ JSON:',
			'{"complexity":"simple|medium|hard","subAgent":"quick_responder|implementation_agent|planning_agent","requiresVision":true,"reason":"ç®€çŸ­ç†ç”±","confidence":0.0}',
			'',
			`ChatMode: ${chatMode}`,
			`AgentMode: ${isAgentMode}`,
			`AttachedFiles: ${context.files.length}`,
			`HasVisionInputs: ${hasVisionInputs}`,
			`UserMessage: ${userMessage}`
		].join('\n');

		try {
			const response = await fetch(this.API_ENDPOINT, {
				method: 'POST',
				headers: {
					'Content-Type': 'application/json',
					'Authorization': `Bearer ${this.getApiKey()}`
				},
				body: JSON.stringify({
					model: this.ROUTER_MODEL,
					messages: [
						{ role: 'system', content: 'ä½ æ˜¯ä¸¥è°¨çš„ä»»åŠ¡éš¾åº¦è¯„ä¼°å™¨ã€‚è¾“å‡ºå¿…é¡»æ˜¯åˆæ³• JSONã€‚' },
						{ role: 'user', content: prompt }
					],
					temperature: 0.1,
					max_tokens: 300,
					stream: false
				})
			});

			if (!response.ok) {
				this.logService.warn(`[GLMChatService] Router model failed: ${response.status}, fallback to heuristic`);
				return this.getFallbackRoutingPlan(userMessage);
			}

			const data = await response.json();
			const content = data?.choices?.[0]?.message?.content || '';
			const match = content.match(/\{[\s\S]*\}/);
			if (!match) {
				this.logService.warn('[GLMChatService] Router JSON not found, fallback to heuristic');
				return this.getFallbackRoutingPlan(userMessage);
			}

			const parsed = JSON.parse(match[0]) as {
				complexity?: 'simple' | 'medium' | 'hard';
				subAgent?: 'quick_responder' | 'implementation_agent' | 'planning_agent';
				requiresVision?: boolean;
				reason?: string;
				confidence?: number;
			};

			const complexity = parsed.complexity ?? 'medium';
			const subAgent = parsed.subAgent ?? (complexity === 'hard' ? 'planning_agent' : complexity === 'simple' ? 'quick_responder' : 'implementation_agent');
			const confidence = typeof parsed.confidence === 'number' ? parsed.confidence : 0.7;
			const requiresVision = Boolean(parsed.requiresVision) || hasVisionInputs;
			const routedModel = requiresVision ? this.getVisionModelByComplexity(complexity) : this.getModelByComplexity(complexity);

			const plan: GLMTaskRoutingPlan = {
				complexity,
				subAgent,
				model: routedModel,
				requiresVision,
				enableThinking: complexity !== 'simple',
				enableWebSearch: complexity !== 'simple',
				maxTokens: complexity === 'hard' ? 32768 : complexity === 'medium' ? 16384 : 8192,
				reason: parsed.reason || 'GLM-5 è·¯ç”±è¯„ä¼°',
				confidence
			};

			this.logService.info(`[GLMChatService] Routing plan: complexity=${plan.complexity}, subAgent=${plan.subAgent}, vision=${plan.requiresVision}, model=${plan.model}, confidence=${plan.confidence}`);
			return plan;
		} catch (error) {
			this.logService.warn(`[GLMChatService] Router error, fallback to heuristic: ${String(error)}`);
			return this.getFallbackRoutingPlan(userMessage);
		}
	}

	/**
	 * æ£€æŸ¥æ·±åº¦æ€è€ƒæ¨¡å¼æ˜¯å¦å¼€å¯ï¼ˆé»˜è®¤å¼€å¯ï¼‰
	 */
	isThinkingEnabled(): boolean {
		return this.configurationService.getValue<boolean>('aiCore.enableThinking') !== false;
	}

	/**
	 * æ£€æŸ¥è”ç½‘æœç´¢æ˜¯å¦å¼€å¯ï¼ˆé»˜è®¤å¼€å¯ï¼Œå¼ºåˆ¶å¼€å¯ï¼‰
	 */
	isWebSearchEnabled(): boolean {
		// è”ç½‘æœç´¢å¼ºåˆ¶å¼€å¯ï¼Œä¸å¯å…³é—­
		return true;
	}

	/**
	 * è·å–æœç´¢å¼•æ“ç±»å‹
	 */
	private getSearchEngine(): 'search_std' | 'search_pro' | 'search_pro_sogou' | 'search_pro_quark' {
		return this.configurationService.getValue<'search_std' | 'search_pro'>('aiCore.searchEngine') || 'search_pro';
	}

	async testConnection(): Promise<boolean> {
		try {
			const response = await fetch(this.API_ENDPOINT, {
				method: 'POST',
				headers: {
					'Content-Type': 'application/json',
					'Authorization': `Bearer ${this.getApiKey()}`
				},
				body: JSON.stringify({
					model: this.getModel(),
					messages: [{ role: 'user', content: 'Hello' }],
					max_tokens: 10,
					stream: false
				})
			});

			if (response.ok) {
				this.logService.info('[GLMChatService] Connection test successful');
				return true;
			}
			return false;
		} catch (error) {
			this.logService.error(`[GLMChatService] Connection test failed: ${String(error)}`);
			return false;
		}
	}

	/**
	 * æ‰§è¡Œè”ç½‘æœç´¢
	 * å‚è€ƒ: https://docs.bigmodel.cn/cn/guide/tools/web-search
	 * ä½¿ç”¨æ™ºè°± AI çš„ Chat API + web_search å·¥å…·
	 */
	async webSearch(query: string): Promise<WebSearchResult[]> {
		const apiKey = this.getApiKey();
		const searchEngine = this.getSearchEngine();

		this.logService.info(`[GLMChatService] Web search: "${query}" using ${searchEngine}`);

		try {
			// ä½¿ç”¨ Chat API å¹¶å¯ç”¨ web_search å·¥å…·
			const response = await fetch(this.API_ENDPOINT, {
				method: 'POST',
				headers: {
					'Content-Type': 'application/json',
					'Authorization': `Bearer ${apiKey}`
				},
				body: JSON.stringify({
					model: this.DEFAULT_MODEL,
					messages: [{ role: 'user', content: query }],
					tools: [{
						type: 'web_search',
						web_search: {
							enable: true,
							search_engine: searchEngine,
							search_result: true
						}
					}],
					stream: false
				})
			});

			if (!response.ok) {
				const errData = await response.json().catch(() => ({}));
				this.logService.error(`[GLMChatService] Web search failed: ${response.status} - ${JSON.stringify(errData)}`);
				return [];
			}

			const data = await response.json();
			this.logService.trace(`[GLMChatService] Web search response: ${JSON.stringify(data).slice(0, 500)}`);

			// è§£ææœç´¢ç»“æœ - æ£€æŸ¥ web_search è¿”å›æ ¼å¼
			const results: WebSearchResult[] = [];

			// æ–¹å¼1: ä» tool_calls ä¸­æå–
			if (data.choices?.[0]?.message?.tool_calls) {
				for (const toolCall of data.choices[0].message.tool_calls) {
					if (toolCall.type === 'web_browser' && toolCall.web_browser?.outputs) {
						for (const output of toolCall.web_browser.outputs) {
							results.push({
								title: output.title || '',
								link: output.link || '',
								content: output.content || '',
								media: output.media,
								icon: output.icon
							});
						}
					}
					// æ–¹å¼2: web_search ç±»å‹
					if (toolCall.type === 'web_search' && toolCall.web_search) {
						const ws = toolCall.web_search;
						if (ws.search_result) {
							for (const result of ws.search_result) {
								results.push({
									title: result.title || '',
									link: result.link || result.url || '',
									content: result.content || result.snippet || '',
									media: result.media,
									icon: result.icon
								});
							}
						}
					}
				}
			}

			// æ–¹å¼3: ä» web_search å­—æ®µæå–ï¼ˆæŸäº› API ç‰ˆæœ¬ï¼‰
			if (data.web_search && Array.isArray(data.web_search)) {
				for (const item of data.web_search) {
					results.push({
						title: item.title || '',
						link: item.link || item.url || '',
						content: item.content || item.snippet || '',
						media: item.media,
						icon: item.icon
					});
				}
			}

			this.logService.info(`[GLMChatService] Web search returned ${results.length} results`);
			return results;
		} catch (error) {
			this.logService.error(`[GLMChatService] Web search error: ${String(error)}`);
			return [];
		}
	}

	buildSystemPrompt(context: GLMChatContext, mode: 'chat' | 'agent', chatMode?: 'vibe' | 'spec'): string {
		let prompt = '';

		// æ ¹æ® Chat æ¨¡å¼ï¼ˆVibe/Specï¼‰è®¾ç½®åŸºç¡€æç¤ºè¯
		if (chatMode === 'spec') {
			prompt = `ä½ æ˜¯ä¸€ä¸ªè§„èŒƒé©±åŠ¨çš„ AI ç¼–ç¨‹åŠ©æ‰‹ï¼Œå·¥ä½œåœ¨ **Spec æ¨¡å¼**ã€‚

## å·¥ä½œæ–¹å¼
ä½ å°†å¸®åŠ©ç”¨æˆ·æŒ‰ä»¥ä¸‹é˜¶æ®µå®Œæˆéœ€æ±‚ï¼š

### é˜¶æ®µ 1: éœ€æ±‚ç†è§£
- ç†è§£ç”¨æˆ·çš„æ ¸å¿ƒéœ€æ±‚ï¼Œæ¾„æ¸…æ¨¡ç³Šçš„åœ°æ–¹

### é˜¶æ®µ 2: ç”¨æˆ·æ•…äº‹ç”Ÿæˆ
å°†éœ€æ±‚æ‹†è§£ä¸ºç”¨æˆ·æ•…äº‹ï¼Œæ¯ä¸ªæ•…äº‹åŒ…å«ï¼š
- æ ‡é¢˜å’Œæè¿°ï¼ˆAs a... I want... So that...ï¼‰
- éªŒæ”¶æ ‡å‡†ï¼ˆAcceptance Criteriaï¼Œè‡³å°‘3æ¡ï¼‰
- ä¼˜å…ˆçº§ï¼ˆé«˜/ä¸­/ä½ï¼‰

### é˜¶æ®µ 3: æŠ€æœ¯è®¾è®¡
ç”ŸæˆæŠ€æœ¯è®¾è®¡æ–‡æ¡£ï¼š
- æ¶æ„æ¦‚è¿°
- ç»„ä»¶è®¾è®¡
- æ•°æ®æµ
- æµ‹è¯•ç­–ç•¥

### é˜¶æ®µ 4: ä»»åŠ¡åˆ†è§£
å°†ç”¨æˆ·æ•…äº‹å’Œè®¾è®¡è½¬åŒ–ä¸ºå¯æ‰§è¡Œçš„ä»»åŠ¡æ¸…å•

### é˜¶æ®µ 5: ä»»åŠ¡æ‰§è¡Œ
é€ä¸ªæ‰§è¡Œä»»åŠ¡ï¼Œæ¯ä¸ªä»»åŠ¡å®Œæˆåæ˜¾ç¤ºè¿›åº¦

è¯·ç”¨ç»“æ„åŒ–çš„ Markdown æ ¼å¼è¾“å‡ºã€‚

`;
		} else if (mode === 'agent') {
			prompt = `ä½ æ˜¯ä¸€ä¸ªæ•æ·çš„ AI ç¼–ç¨‹åŠ©æ‰‹ï¼Œå·¥ä½œåœ¨ **Vibe æ¨¡å¼**ã€‚

## å·¥ä½œé£æ ¼
- å¿«é€Ÿå“åº”ï¼Œè¾¹èŠè¾¹åš
- ç›´æ¥ç»™å‡ºè§£å†³æ–¹æ¡ˆå’Œä»£ç 
- è¿­ä»£å¼æ”¹è¿›ï¼Œæ ¹æ®åé¦ˆè°ƒæ•´

## å¯ç”¨å·¥å…·
- è¯»å–å’Œåˆ†æä»£ç æ–‡ä»¶ (read_file)
- æœç´¢é¡¹ç›®ä¸­çš„ä»£ç  (grep_search, search_files)
- ä¿®æ”¹å’Œåˆ›å»ºæ–‡ä»¶ (write_file) - éœ€è¦ç”¨æˆ·ç¡®è®¤
- æ‰§è¡Œç»ˆç«¯å‘½ä»¤ (run_command)
- è¯Šæ–­å’Œä¿®å¤é”™è¯¯ (get_diagnostics)
- æµè§ˆç½‘é¡µ (browse_url) - è®¿é—®ä»»æ„ URL
- æ·±åº¦æœç´¢ (web_search_deep) - æœç´¢å¹¶ç»¼åˆåˆ†æ

## é‡è¦
- ä¸è¦è¯´"æˆ‘æ— æ³•è®¿é—®é“¾æ¥"ï¼Œä½ æœ‰å·¥å…·å¯ä»¥åšåˆ°
- ä¿æŒç®€æ´é«˜æ•ˆ

è¯·ç”¨ä¸­æ–‡å›ç­”ã€‚

`;
		} else {
			prompt = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¼–ç¨‹åŠ©æ‰‹ã€‚è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œæ“…é•¿ä»£ç åˆ†æå’ŒæŠ€æœ¯è§£é‡Šã€‚

`;
		}

		// æ·»åŠ ä¸Šä¸‹æ–‡æ–‡ä»¶ä¿¡æ¯
		if (context.files.length > 0) {
			prompt += '## ç”¨æˆ·æä¾›çš„ä»£ç ä¸Šä¸‹æ–‡\n\n';

			for (const file of context.files) {
				const fileName = file.path.split('/').pop() || file.path;
				const lineInfo = file.lineRange ? `:${file.lineRange}` : '';

				prompt += `### ğŸ“„ ${fileName}${lineInfo}\n\n`;
				prompt += '```' + (file.language || '') + '\n';
				prompt += file.content;
				prompt += '\n```\n\n';
			}
		}

		// æ·»åŠ è”ç½‘æœç´¢ç»“æœ
		if (context.webSearchResults && context.webSearchResults.length > 0) {
			prompt += '## è”ç½‘æœç´¢ç»“æœ\n\n';
			prompt += '**é‡è¦æç¤º**ï¼šä»¥ä¸‹æ˜¯å·²ç»ä¸ºä½ æ£€ç´¢åˆ°çš„äº’è”ç½‘èµ„æ–™ï¼Œä½ ä¸éœ€è¦å†è®¿é—®è¿™äº›é“¾æ¥ã€‚è¯·ç›´æ¥æ ¹æ®è¿™äº›å·²æä¾›çš„ä¿¡æ¯æ¥å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œå¹¶åœ¨å›ç­”ä¸­å¼•ç”¨ç›¸å…³æ¥æºã€‚\n\n';

			for (const result of context.webSearchResults) {
				prompt += `### ğŸ“„ ${result.title}\n`;
				prompt += `- é“¾æ¥: ${result.link}\n`;
				if (result.media) {
					prompt += `- æ¥æº: ${result.media}\n`;
				}
				if (result.content) {
					prompt += `- æ‘˜è¦: ${result.content}\n`;
				}
				prompt += '\n';
			}

			prompt += 'è¯·åŸºäºä»¥ä¸Šæœç´¢ç»“æœï¼Œç»“åˆä½ çš„çŸ¥è¯†ï¼Œä¸ºç”¨æˆ·æä¾›å®Œæ•´çš„ç­”æ¡ˆã€‚ä¸è¦è¯´"æ— æ³•è®¿é—®é“¾æ¥"æˆ–"æˆ‘æ— æ³•æ‰“å¼€ç½‘é¡µ"ç­‰ï¼Œå› ä¸ºå†…å®¹å·²ç»æä¾›ç»™ä½ äº†ã€‚\n\n';
		}

		return prompt;
	}

	async *streamChat(
		messages: GLMMessage[],
		context: GLMChatContext,
		options?: GLMChatOptions,
		token?: CancellationToken
	): AsyncIterable<GLMStreamEvent> {
		const apiKey = this.getApiKey();
		const model = options?.model || this.getModel();
		const sessionId = options?.sessionId || this._currentSessionId;

		// é‡è¦ï¼šåˆ›å»ºæ¶ˆæ¯çš„æ·±æ‹·è´ï¼Œé¿å…ä¿®æ”¹åŸå§‹ä¼šè¯å†å²
		const messagesCopy = messages.map(m => ({ ...m }));

		// æ£€æŸ¥æ˜¯å¦å¯ç”¨æ·±åº¦æ€è€ƒå’Œè”ç½‘æœç´¢
		const enableThinking = options?.enableThinking ?? this.isThinkingEnabled();
		const enableWebSearch = options?.enableWebSearch ?? this.isWebSearchEnabled();

		this.logService.info(`[GLMChatService] Chat options: thinking=${enableThinking}, webSearch=${enableWebSearch}, messages=${messagesCopy.length}`);

		// å¦‚æœå¯ç”¨è”ç½‘æœç´¢ï¼Œå…ˆæ‰§è¡Œæœç´¢
		if (enableWebSearch) {
			// ä»ç”¨æˆ·æ¶ˆæ¯ä¸­æå–æœç´¢å…³é”®è¯ï¼ˆä½¿ç”¨æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ï¼‰
			const userMessages = messagesCopy.filter(m => m.role === 'user');
			const lastUserMessage = userMessages[userMessages.length - 1]?.content || '';
			if (lastUserMessage) {
				yield { type: 'thinking', content: 'ğŸ” æ­£åœ¨è”ç½‘æœç´¢ç›¸å…³èµ„æ–™...' };

				const searchResults = await this.webSearch(lastUserMessage);
				if (searchResults.length > 0) {
					context.webSearchResults = searchResults;
					yield {
						type: 'web_search',
						content: `æ‰¾åˆ° ${searchResults.length} æ¡ç›¸å…³ç»“æœ`,
						webSearchResults: searchResults
					};

					// æ›´æ–°ç³»ç»Ÿæç¤ºè¯ä»¥åŒ…å«æœç´¢ç»“æœï¼ˆåªä¿®æ”¹å‰¯æœ¬ï¼‰
					const systemMessage = messagesCopy.find(m => m.role === 'system');
					if (systemMessage) {
						systemMessage.content = this.buildSystemPrompt(context, 'chat');
					}
				}
			}
		}

		// æ„å»ºè¯·æ±‚ä½“ï¼ˆä½¿ç”¨å‰¯æœ¬ï¼Œä¿æŠ¤åŸå§‹ä¼šè¯å†å²ï¼‰
		const requestBody: Record<string, unknown> = {
			model,
			messages: messagesCopy,
			temperature: options?.temperature ?? 0.7,
			max_tokens: options?.maxTokens ?? 32768, // GLM-4.7 æ”¯æŒ 128Kï¼Œå¢åŠ è¾“å‡ºé™åˆ¶
			stream: true
		};

		// æ·»åŠ æ·±åº¦æ€è€ƒæ¨¡å¼
		// å‚è€ƒ: https://docs.bigmodel.cn/cn/guide/capabilities/thinking
		if (enableThinking) {
			requestBody.thinking = {
				type: 'enabled',
				budget_tokens: 4096  // æ€è€ƒ token é¢„ç®—
			};
		}

		// æ·»åŠ å·¥å…·å®šä¹‰ï¼ˆå¦‚æœæœ‰ï¼‰
		const tools: GLMToolDefinition[] = options?.tools || [];

		// å¦‚æœå¯ç”¨è”ç½‘æœç´¢ï¼Œæ·»åŠ  web_search å·¥å…·
		if (enableWebSearch && !context.webSearchResults?.length) {
			tools.push({
				type: 'web_search',
				web_search: {
					enable: true,
					search_engine: this.getSearchEngine(),
					search_result: true
				}
			});
		}

		if (tools.length > 0) {
			requestBody.tools = tools;
			requestBody.tool_choice = 'auto';
		}

		this.logService.trace(`[GLMChatService] Sending request to ${this.API_ENDPOINT}`);
		this.logService.trace(`[GLMChatService] Request body: ${JSON.stringify(requestBody).slice(0, 500)}...`);

		try {
			const response = await fetch(this.API_ENDPOINT, {
				method: 'POST',
				headers: {
					'Content-Type': 'application/json',
					'Authorization': `Bearer ${apiKey}`
				},
				body: JSON.stringify(requestBody)
			});

			if (!response.ok) {
				const errorData = await response.json().catch(() => ({}));
				const errorMessage = errorData.error?.message || response.statusText;
				yield { type: 'error', error: `API Error: ${response.status} - ${errorMessage}` };
				return;
			}

			const reader = response.body?.getReader();
			if (!reader) {
				yield { type: 'error', error: 'No response body' };
				return;
			}

			const decoder = new TextDecoder();
			let buffer = '';
			let isInThinkingBlock = false;

			while (true) {
				if (token?.isCancellationRequested) {
					reader.cancel();
					break;
				}

				const { done, value } = await reader.read();
				if (done) {
					break;
				}

				buffer += decoder.decode(value, { stream: true });
				const lines = buffer.split('\n');
				buffer = lines.pop() ?? '';

				for (const line of lines) {
					if (!line.startsWith('data: ')) {
						continue;
					}

					const data = line.slice(6).trim();
					if (data === '[DONE]') {
						yield { type: 'done' };
						continue;
					}

					try {
						const parsed = JSON.parse(data);
						const choice = parsed.choices?.[0];

						// æå–å¹¶æ›´æ–°ç¼“å­˜ç»Ÿè®¡ï¼ˆä¸Šä¸‹æ–‡ç¼“å­˜åŠŸèƒ½ï¼‰
						if (parsed.usage && sessionId) {
							this.updateCacheStats(sessionId, parsed.usage);
						}

						if (!choice) {
							continue;
						}

						const delta = choice.delta;

						// å¤„ç†æ€è€ƒå†…å®¹ï¼ˆæ·±åº¦æ€è€ƒæ¨¡å¼ï¼‰
						if (delta?.reasoning_content) {
							if (!isInThinkingBlock) {
								isInThinkingBlock = true;
								yield { type: 'thinking', content: 'ğŸ’­ æ€è€ƒä¸­...\n' };
							}
							yield { type: 'thinking', content: delta.reasoning_content };
						}

						// å¤„ç†å·¥å…·è°ƒç”¨
						if (delta?.tool_calls) {
							for (const toolCall of delta.tool_calls) {
								// æ£€æŸ¥æ˜¯å¦æ˜¯ web_search å·¥å…·
								if (toolCall.type === 'web_browser') {
									yield {
										type: 'web_search',
										content: 'ğŸ” æ­£åœ¨æœç´¢ç½‘ç»œ...'
									};
								} else {
									yield {
										type: 'tool_call',
										toolCall: {
											id: toolCall.id || '',
											type: 'function',
											function: {
												name: toolCall.function?.name || '',
												arguments: toolCall.function?.arguments || ''
											}
										}
									};
								}
							}
						}

						// å¤„ç†å†…å®¹è¾“å‡º
						if (delta?.content) {
							if (isInThinkingBlock) {
								isInThinkingBlock = false;
								yield { type: 'content', content: '\n\n---\n\n' };
							}
							yield { type: 'content', content: delta.content };
						}

						// æ£€æµ‹æ˜¯å¦å›  token é™åˆ¶è€Œä¸­æ–­
						const finishReason = choice.finish_reason;
						if (finishReason === 'length') {
							this.logService.warn('[GLMChatService] Response truncated due to token limit, signaling continuation needed');
							yield { type: 'truncated', reason: 'length' };
						}

					} catch {
						// å¿½ç•¥è§£æé”™è¯¯
					}
				}
			}

		} catch (error) {
			if (token?.isCancellationRequested) {
				return;
			}
			yield { type: 'error', error: String(error) };
		}
	}

	/**
	 * æ”¯æŒè‡ªåŠ¨ç»­æ¥çš„æµå¼èŠå¤©
	 * å½“å“åº”å›  token é™åˆ¶æˆªæ–­æ—¶ï¼Œè‡ªåŠ¨å‘èµ·ç»­æ¥è¯·æ±‚
	 */
	async *streamChatWithContinuation(
		messages: GLMMessage[],
		context: GLMChatContext,
		options?: GLMChatOptions,
		token?: CancellationToken,
		maxContinuations: number = 3
	): AsyncGenerator<GLMStreamEvent> {
		let continuationCount = 0;
		let currentMessages = [...messages];
		let accumulatedContent = '';

		while (continuationCount <= maxContinuations) {
			let needsContinuation = false;

			for await (const event of this.streamChat(currentMessages, context, options, token)) {
				if (event.type === 'content') {
					accumulatedContent += event.content;
				}

				if (event.type === 'truncated') {
					needsContinuation = true;
					this.logService.info(`[GLMChatService] Continuation ${continuationCount + 1}/${maxContinuations}`);
					continue;
				}

				yield event;
			}

			if (!needsContinuation) {
				break;
			}

			// å‡†å¤‡ç»­æ¥è¯·æ±‚
			continuationCount++;
			if (continuationCount > maxContinuations) {
				yield { type: 'content', content: '\n\nâš ï¸ å›å¤è¿‡é•¿ï¼Œå·²è¾¾åˆ°ç»­æ¥ä¸Šé™ã€‚' };
				break;
			}

			// æ·»åŠ å·²ç”Ÿæˆçš„å†…å®¹ä½œä¸º assistant æ¶ˆæ¯ï¼Œç„¶åè¯·æ±‚ç»§ç»­
			currentMessages = [
				...currentMessages,
				{ role: 'assistant', content: accumulatedContent },
				{ role: 'user', content: 'è¯·ç»§ç»­ä½ çš„å›ç­”ã€‚' }
			];

			yield { type: 'content', content: '\n\n*[ç»§ç»­ç”Ÿæˆä¸­...]*\n\n' };
		}
	}
}

registerSingleton(IGLMChatService, GLMChatService, InstantiationType.Delayed);
